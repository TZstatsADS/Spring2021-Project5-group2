{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import sklearn.metrics\n",
    "import sklearn \n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                    id isRetweet isDeleted              device  favorites  \\\n",
       "0    98454970654916608         f         f           TweetDeck         49   \n",
       "1  1234653427789070336         f         f  Twitter for iPhone      73748   \n",
       "2  1218010753434820614         t         f  Twitter for iPhone          0   \n",
       "3  1304875170860015617         f         f  Twitter for iPhone      80527   \n",
       "4  1218159531554897920         t         f  Twitter for iPhone          0   \n",
       "\n",
       "   retweets                 date isFlagged  Topic  \n",
       "0       255  2011-08-02 18:07:48         f      0  \n",
       "1     17404  2020-03-03 01:34:50         f      6  \n",
       "2      7396  2020-01-17 03:22:47         f      6  \n",
       "3     23502  2020-09-12 20:10:58         f      5  \n",
       "4      9081  2020-01-17 13:13:59         f      9  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>isRetweet</th>\n      <th>isDeleted</th>\n      <th>device</th>\n      <th>favorites</th>\n      <th>retweets</th>\n      <th>date</th>\n      <th>isFlagged</th>\n      <th>Topic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>98454970654916608</td>\n      <td>f</td>\n      <td>f</td>\n      <td>TweetDeck</td>\n      <td>49</td>\n      <td>255</td>\n      <td>2011-08-02 18:07:48</td>\n      <td>f</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1234653427789070336</td>\n      <td>f</td>\n      <td>f</td>\n      <td>Twitter for iPhone</td>\n      <td>73748</td>\n      <td>17404</td>\n      <td>2020-03-03 01:34:50</td>\n      <td>f</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1218010753434820614</td>\n      <td>t</td>\n      <td>f</td>\n      <td>Twitter for iPhone</td>\n      <td>0</td>\n      <td>7396</td>\n      <td>2020-01-17 03:22:47</td>\n      <td>f</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1304875170860015617</td>\n      <td>f</td>\n      <td>f</td>\n      <td>Twitter for iPhone</td>\n      <td>80527</td>\n      <td>23502</td>\n      <td>2020-09-12 20:10:58</td>\n      <td>f</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1218159531554897920</td>\n      <td>t</td>\n      <td>f</td>\n      <td>Twitter for iPhone</td>\n      <td>0</td>\n      <td>9081</td>\n      <td>2020-01-17 13:13:59</td>\n      <td>f</td>\n      <td>9</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "df=pd.read_csv('../output/tweets_with_topic_label.csv')\n",
    "df=df.drop(columns=['text'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "f    55479\n",
       "t     1092\n",
       "Name: isDeleted, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df['isDeleted'].value_counts()\n",
    "# imbalanced data set, consider using smote?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      id  isRetweet  isDeleted  device  favorites  retweets   date  isFlagged  \\\n",
       "0    369          0          0       5         49       255    369          0   \n",
       "1  46117          0          0      18      14214     13112  45744          0   \n",
       "2  44514          1          0      18          0      5991  44161          0   \n",
       "3  52671          0          0      18      15275     15970  52182          0   \n",
       "4  44515          1          0      18          0      7333  44162          0   \n",
       "\n",
       "   Topic  \n",
       "0      0  \n",
       "1      6  \n",
       "2      6  \n",
       "3      5  \n",
       "4      9  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>isRetweet</th>\n      <th>isDeleted</th>\n      <th>device</th>\n      <th>favorites</th>\n      <th>retweets</th>\n      <th>date</th>\n      <th>isFlagged</th>\n      <th>Topic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>369</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>49</td>\n      <td>255</td>\n      <td>369</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>46117</td>\n      <td>0</td>\n      <td>0</td>\n      <td>18</td>\n      <td>14214</td>\n      <td>13112</td>\n      <td>45744</td>\n      <td>0</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>44514</td>\n      <td>1</td>\n      <td>0</td>\n      <td>18</td>\n      <td>0</td>\n      <td>5991</td>\n      <td>44161</td>\n      <td>0</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>52671</td>\n      <td>0</td>\n      <td>0</td>\n      <td>18</td>\n      <td>15275</td>\n      <td>15970</td>\n      <td>52182</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>44515</td>\n      <td>1</td>\n      <td>0</td>\n      <td>18</td>\n      <td>0</td>\n      <td>7333</td>\n      <td>44162</td>\n      <td>0</td>\n      <td>9</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "df=df.apply(preprocessing.LabelEncoder().fit_transform)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(columns=['isDeleted'])\n",
    "Y=df['isDeleted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "majority train class: 44389\nminority train class: 867\nmajority test class: 11090\nminority test class: 225\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test= train_test_split(X,Y,test_size=0.20,random_state=0)\n",
    "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape\n",
    "print('majority train class: %d' % np.sum(Y_train == 0))\n",
    "print('minority train class: %d' % np.sum(Y_train == 1))\n",
    "print('majority test class: %d' % np.sum(Y_test == 0))\n",
    "print('minority test class: %d' % np.sum(Y_test == 1))\n",
    "#imbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "majority train class: 44389\nminority train class: 44389\nmajority test class: 11090\nminority test class: 11090\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "# using SMOTE\n",
    "smt = SMOTE()\n",
    "\n",
    "# fit and apply the transform\n",
    "X_train_smote, Y_train_smote = smt.fit_resample(X_train, Y_train)\n",
    "X_test_smote, Y_test_smote = smt.fit_resample(X_test, Y_test)\n",
    "\n",
    "print('majority train class: %d' % np.sum(Y_train_smote == 0))\n",
    "print('minority train class: %d' % np.sum(Y_train_smote == 1))\n",
    "print('majority test class: %d' % np.sum(Y_test_smote == 0))\n",
    "print('minority test class: %d' % np.sum(Y_test_smote== 1))"
   ]
  },
  {
   "source": [
    "models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training  model takes 0.01 seconds\nPredicting test data takes 0.004 seconds\n              precision    recall  f1-score   support\n\n           0       0.99      0.63      0.77     11090\n           1       0.04      0.82      0.08       225\n\n    accuracy                           0.63     11315\n   macro avg       0.52      0.72      0.42     11315\nweighted avg       0.98      0.63      0.75     11315\n\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestCentroid\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "clf = NearestCentroid()\n",
    "start_time=time.time()\n",
    "clf.fit(X_train, Y_train)\n",
    "NearestCentroid()\n",
    "print(\"Training  model takes %s seconds\" % round((time.time() - start_time),3))\n",
    "\n",
    "start = time.time()\n",
    "pre=clf.predict(X_test)\n",
    "end = time.time()\n",
    "print(\"Predicting test data takes %s seconds\" % round((end - start),3))\n",
    "print(classification_report(Y_test,pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import (NeighborhoodComponentsAnalysis,KNeighborsClassifier)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "for k in range(3,10):\n",
    "    nca = NeighborhoodComponentsAnalysis(random_state=42)\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    nca_pipe = Pipeline([('nca', nca), ('knn', knn)])\n",
    "    nca_pipe.fit(X_train, Y_train)\n",
    "    pre=nca_pipe.predict(X_test)\n",
    "    # Pipeline(...)\n",
    "    print('the score of a model with k = %d is %f' % (k, nca_pipe.score(X_test, Y_test)))\n",
    "    print('the recall of a model with k = %d is %f' % (k, recall_score(Y_test, pre)))\n",
    "    \n",
    "    \n",
    "\n",
    "from sklearn.neighbors import (NeighborhoodComponentsAnalysis,KNeighborsClassifier)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "k=3\n",
    "nca = NeighborhoodComponentsAnalysis(random_state=42)\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "nca_pipe = Pipeline([('nca', nca), ('knn', knn)])\n",
    "nca_pipe.fit(X_train, Y_train)\n",
    "# Pipeline(...)\n",
    "pre=nca_pipe.predict(X_test)\n",
    "# Pipeline(...)\n",
    "print('the score of a model with k = %d is %f' % (k, nca_pipe.score(X_test, Y_test)))\n",
    "print('the recall of a model with k = %d is %f' % (k, recall_score(y_test, pre)))\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "pre=nca_pipe.predict(X_test)\n",
    "print(classification_report(Y_test,pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training  model takes 0.367 seconds\nPredicting test data takes 0.003 seconds\n              precision    recall  f1-score   support\n\n           0       0.98      0.91      0.95     11090\n           1       0.07      0.29      0.11       225\n\n    accuracy                           0.90     11315\n   macro avg       0.52      0.60      0.53     11315\nweighted avg       0.97      0.90      0.93     11315\n\n"
     ]
    }
   ],
   "source": [
    "# SGD with penalty=l1\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "clf = SGDClassifier(loss=\"log\", penalty=\"l1\", max_iter=200, shuffle=True, class_weight='balanced')\n",
    "start_time=time.time()\n",
    "clf.fit(X_train, Y_train)\n",
    "print(\"Training  model takes %s seconds\" % round((time.time() - start_time),3))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "start = time.time()\n",
    "pre=clf.predict(X_test)\n",
    "end = time.time()\n",
    "print(\"Predicting test data takes %s seconds\" % round((end - start),3))\n",
    "print(classification_report(Y_test,pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training  model takes 0.354 seconds\nPredicting test data takes 0.002 seconds\n              precision    recall  f1-score   support\n\n           0       1.00      0.19      0.32     11090\n           1       0.02      0.96      0.05       225\n\n    accuracy                           0.20     11315\n   macro avg       0.51      0.58      0.18     11315\nweighted avg       0.98      0.20      0.31     11315\n\n"
     ]
    }
   ],
   "source": [
    "# SGD with penalty=l2\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "clf = SGDClassifier(loss=\"log\", penalty=\"l2\", max_iter=200, shuffle=True, class_weight='balanced')\n",
    "start_time=time.time()\n",
    "clf.fit(X_train, Y_train)\n",
    "print(\"Training  model takes %s seconds\" % round((time.time() - start_time),3))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "start = time.time()\n",
    "pre=clf.predict(X_test)\n",
    "end = time.time()\n",
    "print(\"Predicting test data takes %s seconds\" % round((end - start),3))\n",
    "print(classification_report(Y_test,pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training  model takes 0.065 seconds\nPredicting test data takes 0.003 seconds\n              precision    recall  f1-score   support\n\n           0       1.00      0.82      0.90     11090\n           1       0.09      0.84      0.16       225\n\n    accuracy                           0.82     11315\n   macro avg       0.54      0.83      0.53     11315\nweighted avg       0.98      0.82      0.88     11315\n\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(max_depth = 30, min_samples_leaf=2, max_leaf_nodes=3, class_weight='balanced')\n",
    "start_time=time.time()\n",
    "clf = clf.fit(X_train, Y_train)\n",
    "print(\"Training  model takes %s seconds\" % round((time.time() - start_time),3))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "start = time.time()\n",
    "pre=clf.predict(X_test)\n",
    "end = time.time()\n",
    "print(\"Predicting test data takes %s seconds\" % round((end - start),3))\n",
    "print(classification_report(Y_test,pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training  model takes 9.249 seconds\n",
      "Predicting test data takes 0.321 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     11090\n",
      "           1       0.91      0.40      0.56       225\n",
      "\n",
      "    accuracy                           0.99     11315\n",
      "   macro avg       0.95      0.70      0.78     11315\n",
      "weighted avg       0.99      0.99      0.98     11315\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=300, class_weight='balanced')\n",
    "start_time=time.time()\n",
    "clf = clf.fit(X_train, Y_train)\n",
    "print(\"Training  model takes %s seconds\" % round((time.time() - start_time),3))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "start = time.time()\n",
    "pre=clf.predict(X_test)\n",
    "end = time.time()\n",
    "print(\"Predicting test data takes %s seconds\" % round((end - start),3))\n",
    "print(classification_report(Y_test,pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training  model takes 6.322 seconds\n",
      "Predicting test data takes 6.876 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     11090\n",
      "           1       0.95      0.34      0.50       225\n",
      "\n",
      "    accuracy                           0.99     11315\n",
      "   macro avg       0.97      0.67      0.75     11315\n",
      "weighted avg       0.99      0.99      0.98     11315\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "clf = AdaBoostClassifier(n_estimators=200)\n",
    "start_time=time.time()\n",
    "clf = clf.fit(X_train, Y_train)\n",
    "print(\"Training  model takes %s seconds\" % round((time.time() - start_time),3))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "start_time=time.time()\n",
    "pre=clf.predict(X_test)\n",
    "end = time.time()\n",
    "print(\"Predicting test data takes %s seconds\" % round((end - start),3))\n",
    "print(classification_report(Y_test,pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python382jvsc74a57bd0cfe7eb89ad1a82021fc53a275945d954d306d66e07a60495d440ee56ebc4ff42",
   "display_name": "Python 3.8.2 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}