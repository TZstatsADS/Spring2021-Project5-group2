{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vaderSentiment in /Users/my_love/opt/anaconda3/lib/python3.8/site-packages (3.3.2)\n",
      "Requirement already satisfied: requests in /Users/my_love/opt/anaconda3/lib/python3.8/site-packages (from vaderSentiment) (2.24.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/my_love/opt/anaconda3/lib/python3.8/site-packages (from requests->vaderSentiment) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/my_love/opt/anaconda3/lib/python3.8/site-packages (from requests->vaderSentiment) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/my_love/opt/anaconda3/lib/python3.8/site-packages (from requests->vaderSentiment) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/my_love/opt/anaconda3/lib/python3.8/site-packages (from requests->vaderSentiment) (3.0.4)\n",
      "Collecting textblob\n",
      "  Downloading textblob-0.15.3-py2.py3-none-any.whl (636 kB)\n",
      "\u001b[K     |████████████████████████████████| 636 kB 4.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: nltk>=3.1 in /Users/my_love/opt/anaconda3/lib/python3.8/site-packages (from textblob) (3.5)\n",
      "Requirement already satisfied, skipping upgrade: regex in /Users/my_love/opt/anaconda3/lib/python3.8/site-packages (from nltk>=3.1->textblob) (2020.10.15)\n",
      "Requirement already satisfied, skipping upgrade: tqdm in /Users/my_love/opt/anaconda3/lib/python3.8/site-packages (from nltk>=3.1->textblob) (4.50.2)\n",
      "Requirement already satisfied, skipping upgrade: joblib in /Users/my_love/opt/anaconda3/lib/python3.8/site-packages (from nltk>=3.1->textblob) (0.17.0)\n",
      "Requirement already satisfied, skipping upgrade: click in /Users/my_love/opt/anaconda3/lib/python3.8/site-packages (from nltk>=3.1->textblob) (7.1.2)\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.15.3\n"
     ]
    }
   ],
   "source": [
    "!pip install vaderSentiment\n",
    "!pip install -U textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "from textblob import TextBlob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex as re\n",
    "import unicodedata\n",
    "import json\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>isRetweet</th>\n",
       "      <th>isDeleted</th>\n",
       "      <th>device</th>\n",
       "      <th>favorites</th>\n",
       "      <th>retweets</th>\n",
       "      <th>date</th>\n",
       "      <th>isFlagged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98454970654916608</td>\n",
       "      <td>Republicans and Democrats have both created ou...</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>TweetDeck</td>\n",
       "      <td>49</td>\n",
       "      <td>255</td>\n",
       "      <td>2011-08-02 18:07:48</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1234653427789070336</td>\n",
       "      <td>I was thrilled to be back in the Great city of...</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>73748</td>\n",
       "      <td>17404</td>\n",
       "      <td>2020-03-03 01:34:50</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1218010753434820614</td>\n",
       "      <td>RT @CBS_Herridge: READ: Letter to surveillance...</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>7396</td>\n",
       "      <td>2020-01-17 03:22:47</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1304875170860015617</td>\n",
       "      <td>The Unsolicited Mail In Ballot Scam is a major...</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>80527</td>\n",
       "      <td>23502</td>\n",
       "      <td>2020-09-12 20:10:58</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1218159531554897920</td>\n",
       "      <td>RT @MZHemingway: Very friendly telling of even...</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>9081</td>\n",
       "      <td>2020-01-17 13:13:59</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56566</th>\n",
       "      <td>1319485303363571714</td>\n",
       "      <td>RT @RandPaul: I don’t know why @JoeBiden think...</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>20683</td>\n",
       "      <td>2020-10-23 03:46:25</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56567</th>\n",
       "      <td>1319484210101379072</td>\n",
       "      <td>RT @EliseStefanik: President @realDonaldTrump ...</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>9869</td>\n",
       "      <td>2020-10-23 03:42:05</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56568</th>\n",
       "      <td>1319444420861829121</td>\n",
       "      <td>RT @TeamTrump: LIVE: Presidential Debate #Deba...</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>8197</td>\n",
       "      <td>2020-10-23 01:03:58</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56569</th>\n",
       "      <td>1319384118849949702</td>\n",
       "      <td>Just signed an order to support the workers of...</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>176289</td>\n",
       "      <td>36001</td>\n",
       "      <td>2020-10-22 21:04:21</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56570</th>\n",
       "      <td>1319345719829008387</td>\n",
       "      <td>Suburban women want Safety &amp;amp; Security. Joe...</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>95169</td>\n",
       "      <td>19545</td>\n",
       "      <td>2020-10-22 18:31:46</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56571 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id                                               text  \\\n",
       "0        98454970654916608  Republicans and Democrats have both created ou...   \n",
       "1      1234653427789070336  I was thrilled to be back in the Great city of...   \n",
       "2      1218010753434820614  RT @CBS_Herridge: READ: Letter to surveillance...   \n",
       "3      1304875170860015617  The Unsolicited Mail In Ballot Scam is a major...   \n",
       "4      1218159531554897920  RT @MZHemingway: Very friendly telling of even...   \n",
       "...                    ...                                                ...   \n",
       "56566  1319485303363571714  RT @RandPaul: I don’t know why @JoeBiden think...   \n",
       "56567  1319484210101379072  RT @EliseStefanik: President @realDonaldTrump ...   \n",
       "56568  1319444420861829121  RT @TeamTrump: LIVE: Presidential Debate #Deba...   \n",
       "56569  1319384118849949702  Just signed an order to support the workers of...   \n",
       "56570  1319345719829008387  Suburban women want Safety &amp; Security. Joe...   \n",
       "\n",
       "      isRetweet isDeleted              device  favorites  retweets  \\\n",
       "0             f         f           TweetDeck         49       255   \n",
       "1             f         f  Twitter for iPhone      73748     17404   \n",
       "2             t         f  Twitter for iPhone          0      7396   \n",
       "3             f         f  Twitter for iPhone      80527     23502   \n",
       "4             t         f  Twitter for iPhone          0      9081   \n",
       "...         ...       ...                 ...        ...       ...   \n",
       "56566         t         f  Twitter for iPhone          0     20683   \n",
       "56567         t         f  Twitter for iPhone          0      9869   \n",
       "56568         t         f  Twitter for iPhone          0      8197   \n",
       "56569         f         f  Twitter for iPhone     176289     36001   \n",
       "56570         f         f  Twitter for iPhone      95169     19545   \n",
       "\n",
       "                      date isFlagged  \n",
       "0      2011-08-02 18:07:48         f  \n",
       "1      2020-03-03 01:34:50         f  \n",
       "2      2020-01-17 03:22:47         f  \n",
       "3      2020-09-12 20:10:58         f  \n",
       "4      2020-01-17 13:13:59         f  \n",
       "...                    ...       ...  \n",
       "56566  2020-10-23 03:46:25         f  \n",
       "56567  2020-10-23 03:42:05         f  \n",
       "56568  2020-10-23 01:03:58         f  \n",
       "56569  2020-10-22 21:04:21         f  \n",
       "56570  2020-10-22 18:31:46         f  \n",
       "\n",
       "[56571 rows x 9 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/tweets_01-08-2021.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://link-springer-com.ezproxy.cul.columbia.edu/content/pdf/10.1007%2F978-3-319-09339-0.pdf (page 617)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add additional feature 'retweeted'\n",
    "tweets = df['text'].to_list()\n",
    "values = []\n",
    "\n",
    "for tweet in tweets:\n",
    "    if tweet.startswith('RT'):\n",
    "        value = True\n",
    "    else:\n",
    "        value = False\n",
    "\n",
    "    values.append(value)\n",
    "    \n",
    "df['retweeted'] = values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Denoising – Remove Username, Hashtags, Links, Change to lowercase\n",
    "def denoise(tweets):\n",
    "    \n",
    "    clean_tweets = []\n",
    "\n",
    "    for tweet in tweets:\n",
    "        result = unicodedata.normalize('NFKD', tweet)\n",
    "        result = re.sub(\"@(\\w{1,15})\", \" \", result) # mentions\n",
    "        result = re.sub(\"#(\\w{1,15})\", \" \", result) # hashtags\n",
    "        result = re.sub(\"https?://([^\\s]+)\", ' ', result) # links\n",
    "        result = re.sub(\"RT\", ' ', result) # RT : \n",
    "        \n",
    "        result = re.sub(\" &amp\", ' ', result) # &amp\n",
    "        result = re.sub(\"[\\n\\r\\t\\0]\", ' ', result) # new line, tabs, etc\n",
    "        \n",
    "        result = re.sub(r\"\\'t\", \"not\", result)\n",
    "        result = re.sub(r\"\\'re\", \" are\", result)\n",
    "        result = re.sub(r\"\\'s\", \" is\", result)\n",
    "        result = re.sub(r\"\\'d\", \" would\", result)\n",
    "        result = re.sub(r\"\\'ll\", \" will\", result)\n",
    "        result = re.sub(r\"\\'ve\", \" have\", result)\n",
    "        result = re.sub(r\"\\'m\", \" am\", result)\n",
    "        \n",
    "        result = re.sub(r'\\b\\w\\b', ' ', result) # sigle letter\n",
    "        result = re.sub('[!,.-;:\\+\\-\\\"“”\\[\\]{}]', ' ', result) # punct\n",
    "        \n",
    "        result = re.sub('\\s{2,}', ' ', result) # 2+ whitespaces\n",
    "\n",
    "        result = result.strip().lower()\n",
    "                \n",
    "        clean_tweets.append(result)\n",
    "        \n",
    "    return clean_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Normalizing contractions\n",
    "# source: https://towardsdatascience.com/text-normalization-7ecc8e084e31\n",
    "\n",
    "def normalize_contractions(tweets):\n",
    "    contraction_list = json.loads(open('../data/english_contractions.json', 'r').read())\n",
    "    clean_tweets = []\n",
    "    \n",
    "    for tweet in tweets:\n",
    "        clean_tweets.append(_normalize_contractions_text(tweet, contraction_list))\n",
    "        \n",
    "    return clean_tweets\n",
    "\n",
    "def _normalize_contractions_text(text, contractions):\n",
    "    \"\"\"\n",
    "    This function normalizes english contractions.\n",
    "    \"\"\"\n",
    "    new_token_list = []\n",
    "    token_list = text.split()\n",
    "    \n",
    "    for word_pos in range(len(token_list)):\n",
    "        word = token_list[word_pos]\n",
    "        first_upper = False\n",
    "        if word[0].isupper():\n",
    "            first_upper = True\n",
    "        if word.lower() in contractions:\n",
    "            replacement = contractions[word.lower()]\n",
    "            if first_upper:\n",
    "                replacement = replacement[0].upper()+replacement[1:]\n",
    "            replacement_tokens = replacement.split()\n",
    "            if len(replacement_tokens)>1:\n",
    "                new_token_list.append(replacement_tokens[0])\n",
    "                new_token_list.append(replacement_tokens[1])\n",
    "            else:\n",
    "                new_token_list.append(replacement_tokens[0])\n",
    "        else:\n",
    "            new_token_list.append(word)\n",
    "    \n",
    "    tweet = \" \".join(new_token_list).strip(\" \")\n",
    "    \n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(tweets):\n",
    "    stopwords_english = stopwords.words('english')\n",
    "    \n",
    "    to_be_removed = [\"haven't\", \"against\", \"not\", \"weren't\", \"won't\", 'no']\n",
    "    \n",
    "    for word in to_be_removed:\n",
    "        stopwords_english.remove(word)\n",
    "        \n",
    "    stopwords_english.append('pm')\n",
    "    stopwords_english.append('am')\n",
    "\n",
    "    clean_tweets = []\n",
    "    \n",
    "    # instantiate the tokenizer class\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, \n",
    "                           strip_handles=True,\n",
    "                           reduce_len=True)\n",
    "    \n",
    "    for tweet in tweets:\n",
    "        \n",
    "        # tokenize the tweets\n",
    "        tweet_tokens = tokenizer.tokenize(tweet)\n",
    "        \n",
    "        tweet_clean = ''\n",
    "        \n",
    "        for word in tweet_tokens: # Go through every word in your tokens list\n",
    "            if word not in stopwords_english:\n",
    "                tweet_clean = tweet_clean + ' ' + word\n",
    "                \n",
    "        clean_tweets.append(tweet_clean.strip())\n",
    "        \n",
    "    return clean_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deEmojify(tweets):\n",
    "    clean_tweets = []\n",
    "    \n",
    "    for tweet in tweets:\n",
    "        regrex_pattern = re.compile(pattern = \"[\"\n",
    "            u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "            u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "            u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "            u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               \"]+\", flags = re.UNICODE)\n",
    "        \n",
    "        clean_tweets.append(regrex_pattern.sub(r'', tweet))    \n",
    "        \n",
    "    return clean_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization_pipeline(tweets):\n",
    "\n",
    "    tweets = denoise(tweets)\n",
    "    tweets = deEmojify(tweets)\n",
    "    tweets = normalize_contractions(tweets)\n",
    "    tweets = remove_stop_words(tweets)\n",
    "\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tweets\n",
    "tweets = df['text'].to_list()\n",
    "\n",
    "clean_tweets = normalization_pipeline(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment_text'] = clean_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_scores(tweet):\n",
    "  \n",
    "    # Create a SentimentIntensityAnalyzer object.\n",
    "    sid_obj = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    sentiment_score = sid_obj.polarity_scores(tweet)['compound'] \n",
    "    blob_dict = TextBlob(tweet).sentiment\n",
    "    \n",
    "    sentiment_vader.append(sentiment_score)\n",
    "    polarity.append(blob_dict.polarity)\n",
    "    subjectivity.append(blob_dict.subjectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute scores\n",
    "tweets_clean = df['sentiment_text']\n",
    "\n",
    "polarity = []\n",
    "subjectivity = []\n",
    "sentiment_vader = []\n",
    "\n",
    "for tweet in tweets_clean:\n",
    "    sentiment_scores(tweet)\n",
    "    \n",
    "df['subjectivity_score'] = subjectivity\n",
    "df['polarity'] = polarity\n",
    "df['sentiment_vader'] = sentiment_vader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rid_of_spine(axes):\n",
    "    for ax in axes:\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting polarity vs sentiment\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16,8), sharey=True)\n",
    "g1 = sns.histplot(x=df['sentiment_vader'], color=\"steelblue\", ax=ax1, bins = 30)\n",
    "g2 = sns.histplot(x=df['polarity'], color=\"steelblue\", ax=ax2, bins = 30)\n",
    "\n",
    "ax1.set_title(\"Vader Sentiment\")\n",
    "ax2.set_title(\"Polarity (TextBlob)\")\n",
    "\n",
    "get_rid_of_spine([ax1, ax2])\n",
    "plt.suptitle(\"The distribution of sentiment scores\", y = 1.03, fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting objectivity\n",
    "# subjectivity_score = 0: very objective\n",
    "# subjectivity_score = 1: very subjective\n",
    "fig, ax = plt.subplots(figsize=(16,8))\n",
    "g1 = sns.histplot(x=df['subjectivity_score'], color=\"steelblue\", bins = 30)\n",
    "get_rid_of_spine([ax])\n",
    "plt.suptitle(\"The distribution of subjectivity score\", y = 1.03, fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'../output/sentiment_analysis_clean.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
