{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "pleasant-penny",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pt\n",
    "import datetime as dt\n",
    "import unicodedata\n",
    "\n",
    "import tweepy as np\n",
    "import regex as re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "# nltk.download('wordnet') ##################### need this line or will get error\n",
    "import string\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "happy-carroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import os, sys\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re,string\n",
    "import nltk\n",
    "# import spacy\n",
    "import sklearn,gensim,tweepy,pyLDAvis\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "finished-fancy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\morrismr\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    id                                               text  \\\n",
      "0    98454970654916608  Republicans and Democrats have both created ou...   \n",
      "1  1234653427789070336  I was thrilled to be back in the Great city of...   \n",
      "2  1218010753434820614  RT @CBS_Herridge: READ: Letter to surveillance...   \n",
      "3  1304875170860015617  The Unsolicited Mail In Ballot Scam is a major...   \n",
      "4  1218159531554897920  RT @MZHemingway: Very friendly telling of even...   \n",
      "\n",
      "  isRetweet isDeleted              device  favorites  retweets  \\\n",
      "0         f         f           TweetDeck         49       255   \n",
      "1         f         f  Twitter for iPhone      73748     17404   \n",
      "2         t         f  Twitter for iPhone          0      7396   \n",
      "3         f         f  Twitter for iPhone      80527     23502   \n",
      "4         t         f  Twitter for iPhone          0      9081   \n",
      "\n",
      "                  date isFlagged  \n",
      "0  2011-08-02 18:07:48         f  \n",
      "1  2020-03-03 01:34:50         f  \n",
      "2  2020-01-17 03:22:47         f  \n",
      "3  2020-09-12 20:10:58         f  \n",
      "4  2020-01-17 13:13:59         f  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# stop = set(stopwords.words('english'))\n",
    "# stopwords = set(stopwords.words('english'))\n",
    "# df = pd.read_csv(r'..\\tweets_01-08-2021.csv')\n",
    "df = pd.read_csv(r'C:\\Users\\morrismr\\Downloads\\tweets_01-08-2021.csv')\n",
    "df.columns\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heated-input",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_for_retweets(text):\n",
    "    if (\"RT @\") in text:\n",
    "        return True\n",
    "    else:\n",
    "        False\n",
    "\n",
    "df['RT'] = df['text'].apply(check_for_retweets)\n",
    "\n",
    "\n",
    "\n",
    "def strip_Text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "    \n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # text = re.sub(\"https?://([^\\s]+)\", ' ', text) # links\n",
    "    # text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text)\n",
    "    \n",
    "    text = re.sub(\"rt\", ' ', text) # RT : \n",
    "    text = re.sub(\" &amp\", ' ', text) # &amp\n",
    "    text = re.sub(\"[\\n\\r\\t\\0]\", ' ', text) # new line, tabs, etc\n",
    "    text = re.sub('[!,.-;:\\\"“”\\[\\]{}]', ' ', text) # punct\n",
    "    text = re.sub('\\s{2,}', ' ', text) # 2+ whitespaces\n",
    "   \n",
    "    return text\n",
    "\n",
    "\n",
    "def clean(doc):\n",
    "    lemma = WordNetLemmatizer()\n",
    "    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
    "    # punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "    normalized = \" \".join(lemma.lemmatize(word) for word in stop_free.split())\n",
    "    return normalized\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acoustic-philadelphia",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_cleaned'] = df['text'].apply(strip_Text)\n",
    "df['text_cleaned'] = df['text_cleaned'].apply(clean)\n",
    "tweets_df=df.loc[:,['text']]\n",
    "tweets_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revised-software",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 56500\n",
    "for i in range(a,a+10):\n",
    "    print(tweets_df.text[i])\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
