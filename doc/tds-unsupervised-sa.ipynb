{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import swifter\n",
    "import numpy as np\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from time import time \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>isRetweet</th>\n",
       "      <th>isDeleted</th>\n",
       "      <th>device</th>\n",
       "      <th>favorites</th>\n",
       "      <th>retweets</th>\n",
       "      <th>date</th>\n",
       "      <th>isFlagged</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>sentiment_text</th>\n",
       "      <th>subjectivity_score</th>\n",
       "      <th>polarity</th>\n",
       "      <th>sentiment_vader</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98454970654916608</td>\n",
       "      <td>Republicans and Democrats have both created ou...</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>TweetDeck</td>\n",
       "      <td>49</td>\n",
       "      <td>255</td>\n",
       "      <td>2011-08-02 18:07:48</td>\n",
       "      <td>f</td>\n",
       "      <td>False</td>\n",
       "      <td>republicans democrats created economic problems</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>-0.1779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1234653427789070336</td>\n",
       "      <td>I was thrilled to be back in the Great city of...</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>73748</td>\n",
       "      <td>17404</td>\n",
       "      <td>2020-03-03 01:34:50</td>\n",
       "      <td>f</td>\n",
       "      <td>False</td>\n",
       "      <td>thrilled back great city charlotte north carol...</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.9771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1218010753434820614</td>\n",
       "      <td>RT @CBS_Herridge: READ: Letter to surveillance...</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>7396</td>\n",
       "      <td>2020-01-17 03:22:47</td>\n",
       "      <td>f</td>\n",
       "      <td>True</td>\n",
       "      <td>read letter surveillance court obtained cbs ne...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1304875170860015617</td>\n",
       "      <td>The Unsolicited Mail In Ballot Scam is a major...</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>80527</td>\n",
       "      <td>23502</td>\n",
       "      <td>2020-09-12 20:10:58</td>\n",
       "      <td>f</td>\n",
       "      <td>False</td>\n",
       "      <td>unsolicited mail ballot scam major threat demo...</td>\n",
       "      <td>0.454762</td>\n",
       "      <td>0.029464</td>\n",
       "      <td>-0.9552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1218159531554897920</td>\n",
       "      <td>RT @MZHemingway: Very friendly telling of even...</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>9081</td>\n",
       "      <td>2020-01-17 13:13:59</td>\n",
       "      <td>f</td>\n",
       "      <td>True</td>\n",
       "      <td>friendly telling events comey apparent leaking...</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.212500</td>\n",
       "      <td>0.4939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                               text  \\\n",
       "0    98454970654916608  Republicans and Democrats have both created ou...   \n",
       "1  1234653427789070336  I was thrilled to be back in the Great city of...   \n",
       "2  1218010753434820614  RT @CBS_Herridge: READ: Letter to surveillance...   \n",
       "3  1304875170860015617  The Unsolicited Mail In Ballot Scam is a major...   \n",
       "4  1218159531554897920  RT @MZHemingway: Very friendly telling of even...   \n",
       "\n",
       "  isRetweet isDeleted              device  favorites  retweets  \\\n",
       "0         f         f           TweetDeck         49       255   \n",
       "1         f         f  Twitter for iPhone      73748     17404   \n",
       "2         t         f  Twitter for iPhone          0      7396   \n",
       "3         f         f  Twitter for iPhone      80527     23502   \n",
       "4         t         f  Twitter for iPhone          0      9081   \n",
       "\n",
       "                  date isFlagged  retweeted  \\\n",
       "0  2011-08-02 18:07:48         f      False   \n",
       "1  2020-03-03 01:34:50         f      False   \n",
       "2  2020-01-17 03:22:47         f       True   \n",
       "3  2020-09-12 20:10:58         f      False   \n",
       "4  2020-01-17 13:13:59         f       True   \n",
       "\n",
       "                                      sentiment_text  subjectivity_score  \\\n",
       "0    republicans democrats created economic problems            0.200000   \n",
       "1  thrilled back great city charlotte north carol...            0.483333   \n",
       "2  read letter surveillance court obtained cbs ne...            0.100000   \n",
       "3  unsolicited mail ballot scam major threat demo...            0.454762   \n",
       "4  friendly telling events comey apparent leaking...            0.425000   \n",
       "\n",
       "   polarity  sentiment_vader  \n",
       "0  0.200000          -0.1779  \n",
       "1  0.450000           0.9771  \n",
       "2  0.100000           0.0000  \n",
       "3  0.029464          -0.9552  \n",
       "4  0.212500           0.4939  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets = pd.read_csv('../output/sentiment_analysis_clean.csv')\n",
    "df_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing empty sentiment_text\n",
    "df_tweets = df_tweets[-df_tweets.sentiment_text.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f30cde7a840a4224a2865ee0dd82cf84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Pandas Apply'), FloatProgress(value=0.0, max=54682.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenizing sentiment_text for compatibility with gensim package\n",
    "df_tweets.sentiment_text = df_tweets.sentiment_text.swifter.apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [republicans, democrats, created, economic, pr...\n",
       "1    [thrilled, back, great, city, charlotte, north...\n",
       "2    [read, letter, surveillance, court, obtained, ...\n",
       "3    [unsolicited, mail, ballot, scam, major, threa...\n",
       "4    [friendly, telling, events, comey, apparent, l...\n",
       "Name: sentiment_text, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets.sentiment_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [tweet for tweet in df_tweets.sentiment_text]\n",
    "phrases = Phrases(corpus, min_count=10)\n",
    "bigram = Phraser(phrases)\n",
    "sentences = bigram[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thrilled_back',\n",
       " 'great',\n",
       " 'city',\n",
       " 'charlotte',\n",
       " 'north_carolina',\n",
       " 'thousands',\n",
       " 'hardworking_american',\n",
       " 'patriots',\n",
       " 'love',\n",
       " 'country',\n",
       " 'cherish',\n",
       " 'values',\n",
       " 'respect',\n",
       " 'laws',\n",
       " 'always',\n",
       " 'put',\n",
       " 'america',\n",
       " 'first',\n",
       " 'thank',\n",
       " 'wonderful',\n",
       " 'evening']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of sentence with bigram token\n",
    "sentences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build vocab: 0.13 mins\n"
     ]
    }
   ],
   "source": [
    "w2v_model = Word2Vec(min_count=1,\n",
    "                     window=7,\n",
    "                     size=1000,\n",
    "                     sample=1e-5, \n",
    "                     alpha=0.03, \n",
    "                     min_alpha=0.0007, \n",
    "                     negative=10,\n",
    "                     workers=-1)\n",
    "\n",
    "start = time()\n",
    "\n",
    "w2v_model.build_vocab(sentences, progress_per=50000)\n",
    "\n",
    "print('Time to build vocab: {} mins'.format(round((time() - start) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model: 4.8 mins\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=200, report_delay=1)\n",
    "\n",
    "print('Time to train the model: {} mins'.format(round((time() - start) / 60, 2)))\n",
    "\n",
    "w2v_model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.save(\"../output/word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = Word2Vec.load(\"../output/word2vec.model\").wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters=2, max_iter=1000, random_state=True, n_init=50).fit(X=word_vectors.vectors.astype('double'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('vulnerabilities', 0.2159450352191925),\n",
       " ('prominently', 0.14896896481513977),\n",
       " ('kilometre', 0.13908886909484863),\n",
       " (\"america'executive\", 0.12984643876552582),\n",
       " ('erd', 0.12770745158195496),\n",
       " ('colours', 0.1274034082889557),\n",
       " ('badly', 0.1264059841632843),\n",
       " ('texas', 0.12568989396095276),\n",
       " ('mulvan', 0.12416908144950867),\n",
       " ('wd', 0.11968011409044266),\n",
       " ('full', 0.11308547854423523),\n",
       " ('cnnpolitics', 0.1126168742775917),\n",
       " ('elemental', 0.11253483593463898),\n",
       " ('damn', 0.1122153103351593),\n",
       " ('interfered', 0.11203218996524811)]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_vector(model.cluster_centers_[0], topn=15, restrict_vocab=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_cluster_index = 1\n",
    "positive_cluster_center = model.cluster_centers_[positive_cluster_index]\n",
    "negative_cluster_center = model.cluster_centers_[1-positive_cluster_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pd.DataFrame(word_vectors.vocab.keys())\n",
    "words.columns = ['words']\n",
    "words['vectors'] = words.words.apply(lambda x: word_vectors[f'{x}'])\n",
    "words['cluster'] = words.vectors.apply(lambda x: model.predict([np.array(x)]))\n",
    "words.cluster = words.cluster.apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "words['cluster_value'] = [1 if i==positive_cluster_index else -1 for i in words.cluster]\n",
    "words['closeness_score'] = words.apply(lambda x: 1/(model.transform([x.vectors]).min()), axis=1)\n",
    "words['sentiment_coeff'] = words.closeness_score * words.cluster_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>vectors</th>\n",
       "      <th>cluster</th>\n",
       "      <th>cluster_value</th>\n",
       "      <th>closeness_score</th>\n",
       "      <th>sentiment_coeff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>republicans</td>\n",
       "      <td>[-0.0017206554, 0.0405393, -0.002171574, 0.008...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.001063</td>\n",
       "      <td>1.001063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>democrats</td>\n",
       "      <td>[0.03469303, -0.054783363, -0.030622007, 0.050...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000302</td>\n",
       "      <td>1.000302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>created</td>\n",
       "      <td>[0.03200076, 0.054269243, 0.030441789, -0.0403...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000064</td>\n",
       "      <td>-1.000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>economic</td>\n",
       "      <td>[-0.012928113, -0.0248307, -0.004927355, 0.045...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000402</td>\n",
       "      <td>1.000402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>problems</td>\n",
       "      <td>[-0.024483873, 0.013157721, -0.010000125, 0.04...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000464</td>\n",
       "      <td>-1.000464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>thrilled_back</td>\n",
       "      <td>[0.040265683, 0.048340615, 0.020265633, -0.041...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000302</td>\n",
       "      <td>1.000302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>great</td>\n",
       "      <td>[0.039128542, -0.00051335985, 0.0025913415, 0....</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000880</td>\n",
       "      <td>-1.000880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>city</td>\n",
       "      <td>[0.0062261526, -0.0453001, 0.028356899, 0.0294...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000161</td>\n",
       "      <td>-1.000161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>charlotte</td>\n",
       "      <td>[0.012756506, 0.003740359, 0.04916424, 0.03295...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000540</td>\n",
       "      <td>-1.000540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>north_carolina</td>\n",
       "      <td>[0.016431287, 0.0074954056, -0.021117482, -0.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000869</td>\n",
       "      <td>1.000869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>thousands</td>\n",
       "      <td>[0.0034027093, 0.052831355, -0.048572004, 0.05...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.001607</td>\n",
       "      <td>1.001607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hardworking_american</td>\n",
       "      <td>[-0.024672324, -0.008592887, -0.037715618, 0.0...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.001324</td>\n",
       "      <td>-1.001324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>patriots</td>\n",
       "      <td>[0.0042763515, 0.008495407, 0.01585909, -0.006...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000330</td>\n",
       "      <td>1.000330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>love</td>\n",
       "      <td>[-0.0097958725, -0.026491957, 0.0046977056, -0...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999822</td>\n",
       "      <td>-0.999822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>country</td>\n",
       "      <td>[-0.038528025, 0.0102071045, 0.011774458, -0.0...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000807</td>\n",
       "      <td>-1.000807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cherish</td>\n",
       "      <td>[-0.036907338, -0.020678885, -0.037869576, -0....</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999860</td>\n",
       "      <td>0.999860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>values</td>\n",
       "      <td>[0.024943264, 0.02389953, -0.04024075, 0.03548...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999416</td>\n",
       "      <td>0.999416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>respect</td>\n",
       "      <td>[-0.05028806, 0.029186044, -0.013532096, 0.043...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000405</td>\n",
       "      <td>1.000405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>laws</td>\n",
       "      <td>[-0.0058170864, 0.0042653987, 0.017394267, 0.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000249</td>\n",
       "      <td>1.000249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>always</td>\n",
       "      <td>[0.028210972, 0.043390844, 7.457729e-06, -0.00...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999651</td>\n",
       "      <td>0.999651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   words                                            vectors  \\\n",
       "0            republicans  [-0.0017206554, 0.0405393, -0.002171574, 0.008...   \n",
       "1              democrats  [0.03469303, -0.054783363, -0.030622007, 0.050...   \n",
       "2                created  [0.03200076, 0.054269243, 0.030441789, -0.0403...   \n",
       "3               economic  [-0.012928113, -0.0248307, -0.004927355, 0.045...   \n",
       "4               problems  [-0.024483873, 0.013157721, -0.010000125, 0.04...   \n",
       "5          thrilled_back  [0.040265683, 0.048340615, 0.020265633, -0.041...   \n",
       "6                  great  [0.039128542, -0.00051335985, 0.0025913415, 0....   \n",
       "7                   city  [0.0062261526, -0.0453001, 0.028356899, 0.0294...   \n",
       "8              charlotte  [0.012756506, 0.003740359, 0.04916424, 0.03295...   \n",
       "9         north_carolina  [0.016431287, 0.0074954056, -0.021117482, -0.0...   \n",
       "10             thousands  [0.0034027093, 0.052831355, -0.048572004, 0.05...   \n",
       "11  hardworking_american  [-0.024672324, -0.008592887, -0.037715618, 0.0...   \n",
       "12              patriots  [0.0042763515, 0.008495407, 0.01585909, -0.006...   \n",
       "13                  love  [-0.0097958725, -0.026491957, 0.0046977056, -0...   \n",
       "14               country  [-0.038528025, 0.0102071045, 0.011774458, -0.0...   \n",
       "15               cherish  [-0.036907338, -0.020678885, -0.037869576, -0....   \n",
       "16                values  [0.024943264, 0.02389953, -0.04024075, 0.03548...   \n",
       "17               respect  [-0.05028806, 0.029186044, -0.013532096, 0.043...   \n",
       "18                  laws  [-0.0058170864, 0.0042653987, 0.017394267, 0.0...   \n",
       "19                always  [0.028210972, 0.043390844, 7.457729e-06, -0.00...   \n",
       "\n",
       "    cluster  cluster_value  closeness_score  sentiment_coeff  \n",
       "0         1              1         1.001063         1.001063  \n",
       "1         1              1         1.000302         1.000302  \n",
       "2         0             -1         1.000064        -1.000064  \n",
       "3         1              1         1.000402         1.000402  \n",
       "4         0             -1         1.000464        -1.000464  \n",
       "5         1              1         1.000302         1.000302  \n",
       "6         0             -1         1.000880        -1.000880  \n",
       "7         0             -1         1.000161        -1.000161  \n",
       "8         0             -1         1.000540        -1.000540  \n",
       "9         1              1         1.000869         1.000869  \n",
       "10        1              1         1.001607         1.001607  \n",
       "11        0             -1         1.001324        -1.001324  \n",
       "12        1              1         1.000330         1.000330  \n",
       "13        0             -1         0.999822        -0.999822  \n",
       "14        0             -1         1.000807        -1.000807  \n",
       "15        1              1         0.999860         0.999860  \n",
       "16        1              1         0.999416         0.999416  \n",
       "17        1              1         1.000405         1.000405  \n",
       "18        1              1         1.000249         1.000249  \n",
       "19        1              1         0.999651         0.999651  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "words[['words', 'sentiment_coeff']].to_csv('../output/sentiment_dictionary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9db81554d254438ea6f4758b96c2cddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Pandas Apply'), FloatProgress(value=0.0, max=54682.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_tweets.sentiment_text = df_tweets.sentiment_text.swifter.apply(lambda x: ' '.join(bigram[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_labels = [-1, 0, 1]\n",
    "cut_bins = [-1, -0.0000001, 0.0000001, 1]\n",
    "df_tweets['rate'] = pd.cut(df_tweets.sentiment_vader, bins=cut_bins, labels=cut_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>isRetweet</th>\n",
       "      <th>isDeleted</th>\n",
       "      <th>device</th>\n",
       "      <th>favorites</th>\n",
       "      <th>retweets</th>\n",
       "      <th>date</th>\n",
       "      <th>isFlagged</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>sentiment_text</th>\n",
       "      <th>subjectivity_score</th>\n",
       "      <th>polarity</th>\n",
       "      <th>sentiment_vader</th>\n",
       "      <th>rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98454970654916608</td>\n",
       "      <td>Republicans and Democrats have both created ou...</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>TweetDeck</td>\n",
       "      <td>49</td>\n",
       "      <td>255</td>\n",
       "      <td>2011-08-02 18:07:48</td>\n",
       "      <td>f</td>\n",
       "      <td>False</td>\n",
       "      <td>republicans democrats created economic problems</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>-0.1779</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1234653427789070336</td>\n",
       "      <td>I was thrilled to be back in the Great city of...</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>73748</td>\n",
       "      <td>17404</td>\n",
       "      <td>2020-03-03 01:34:50</td>\n",
       "      <td>f</td>\n",
       "      <td>False</td>\n",
       "      <td>thrilled_back great city charlotte north_carol...</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.9771</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1218010753434820614</td>\n",
       "      <td>RT @CBS_Herridge: READ: Letter to surveillance...</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>7396</td>\n",
       "      <td>2020-01-17 03:22:47</td>\n",
       "      <td>f</td>\n",
       "      <td>True</td>\n",
       "      <td>read letter surveillance court obtained cbs ne...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1304875170860015617</td>\n",
       "      <td>The Unsolicited Mail In Ballot Scam is a major...</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>80527</td>\n",
       "      <td>23502</td>\n",
       "      <td>2020-09-12 20:10:58</td>\n",
       "      <td>f</td>\n",
       "      <td>False</td>\n",
       "      <td>unsolicited mail_ballot scam major threat demo...</td>\n",
       "      <td>0.454762</td>\n",
       "      <td>0.029464</td>\n",
       "      <td>-0.9552</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1218159531554897920</td>\n",
       "      <td>RT @MZHemingway: Very friendly telling of even...</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>9081</td>\n",
       "      <td>2020-01-17 13:13:59</td>\n",
       "      <td>f</td>\n",
       "      <td>True</td>\n",
       "      <td>friendly telling events comey apparent leaking...</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.212500</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                               text  \\\n",
       "0    98454970654916608  Republicans and Democrats have both created ou...   \n",
       "1  1234653427789070336  I was thrilled to be back in the Great city of...   \n",
       "2  1218010753434820614  RT @CBS_Herridge: READ: Letter to surveillance...   \n",
       "3  1304875170860015617  The Unsolicited Mail In Ballot Scam is a major...   \n",
       "4  1218159531554897920  RT @MZHemingway: Very friendly telling of even...   \n",
       "\n",
       "  isRetweet isDeleted              device  favorites  retweets  \\\n",
       "0         f         f           TweetDeck         49       255   \n",
       "1         f         f  Twitter for iPhone      73748     17404   \n",
       "2         t         f  Twitter for iPhone          0      7396   \n",
       "3         f         f  Twitter for iPhone      80527     23502   \n",
       "4         t         f  Twitter for iPhone          0      9081   \n",
       "\n",
       "                  date isFlagged  retweeted  \\\n",
       "0  2011-08-02 18:07:48         f      False   \n",
       "1  2020-03-03 01:34:50         f      False   \n",
       "2  2020-01-17 03:22:47         f       True   \n",
       "3  2020-09-12 20:10:58         f      False   \n",
       "4  2020-01-17 13:13:59         f       True   \n",
       "\n",
       "                                      sentiment_text  subjectivity_score  \\\n",
       "0    republicans democrats created economic problems            0.200000   \n",
       "1  thrilled_back great city charlotte north_carol...            0.483333   \n",
       "2  read letter surveillance court obtained cbs ne...            0.100000   \n",
       "3  unsolicited mail_ballot scam major threat demo...            0.454762   \n",
       "4  friendly telling events comey apparent leaking...            0.425000   \n",
       "\n",
       "   polarity  sentiment_vader rate  \n",
       "0  0.200000          -0.1779   -1  \n",
       "1  0.450000           0.9771    1  \n",
       "2  0.100000           0.0000    0  \n",
       "3  0.029464          -0.9552   -1  \n",
       "4  0.212500           0.4939    1  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets[['sentiment_text', 'rate']].to_csv('../output/cleaned_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_file = pd.read_csv('../output/cleaned_dataset.csv')\n",
    "sentiment_map = pd.read_csv('../output/sentiment_dictionary.csv')\n",
    "sentiment_dict = dict(zip(sentiment_map.words.values, sentiment_map.sentiment_coeff.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_weighting = final_file.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darylkow/.pyenv/versions/3.8.5/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=lambda y: y.split(), norm=None)\n",
    "tfidf.fit(file_weighting.sentiment_text)\n",
    "features = pd.Series(tfidf.get_feature_names())\n",
    "transformed = tfidf.transform(file_weighting.sentiment_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tfidf_dictionary(x, transformed_file, features):\n",
    "    '''\n",
    "    create dictionary for each input sentence x, where each word has assigned its tfidf score\n",
    "    \n",
    "    inspired  by function from this wonderful article: \n",
    "    https://medium.com/analytics-vidhya/automated-keyword-extraction-from-articles-using-nlp-bfd864f41b34\n",
    "    \n",
    "    x - row of dataframe, containing sentences, and their indexes,\n",
    "    transformed_file - all sentences transformed with TfidfVectorizer\n",
    "    features - names of all words in corpus used in TfidfVectorizer\n",
    "\n",
    "    '''\n",
    "    vector_coo = transformed_file[x.name].tocoo()\n",
    "    vector_coo.col = features.iloc[vector_coo.col].values\n",
    "    dict_from_coo = dict(zip(vector_coo.col, vector_coo.data))\n",
    "    return dict_from_coo\n",
    "\n",
    "def replace_tfidf_words(x, transformed_file, features):\n",
    "    '''\n",
    "    replacing each word with it's calculated tfidf dictionary with scores of each word\n",
    "    x - row of dataframe, containing sentences, and their indexes,\n",
    "    transformed_file - all sentences transformed with TfidfVectorizer\n",
    "    features - names of all words in corpus used in TfidfVectorizer\n",
    "    '''\n",
    "    dictionary = create_tfidf_dictionary(x, transformed_file, features)   \n",
    "    return list(map(lambda y:dictionary[f'{y}'], x.sentiment_text.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.1 s, sys: 866 ms, total: 19.9 s\n",
      "Wall time: 25.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "replaced_tfidf_scores = file_weighting.apply(lambda x: replace_tfidf_words(x, transformed, features), axis=1)#this step takes around 3-4 minutes minutes to calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_sentiment_words(word, sentiment_dict):\n",
    "    '''\n",
    "    replacing each word with its associated sentiment score from sentiment dict\n",
    "    '''\n",
    "    try:\n",
    "        out = sentiment_dict[word]\n",
    "    except KeyError:\n",
    "        out = 0\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaced_closeness_scores = file_weighting.sentiment_text.apply(lambda x: list(map(lambda y: replace_sentiment_words(y, sentiment_dict), x.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_df = pd.DataFrame(data=[replaced_closeness_scores, replaced_tfidf_scores, file_weighting.sentiment_text, file_weighting.rate]).T\n",
    "replacement_df.columns = ['sentiment_coeff', 'tfidf_scores', 'sentence', 'sentiment']\n",
    "replacement_df['sentiment_rate'] = replacement_df.apply(lambda x: np.array(x.loc['sentiment_coeff']) @ np.array(x.loc['tfidf_scores']), axis=1)\n",
    "replacement_df['prediction'] = (replacement_df.sentiment_rate>0).astype('int8')\n",
    "replacement_df['sentiment'] = [1 if i==1 else 0 for i in replacement_df.sentiment]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13221</td>\n",
       "      <td>10408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17153</td>\n",
       "      <td>13900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1\n",
       "0  13221  10408\n",
       "1  17153  13900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " Scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.495977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.571828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.447622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.502159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             scores\n",
       "accuracy   0.495977\n",
       "precision  0.571828\n",
       "recall     0.447622\n",
       "f1         0.502159"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_classes = replacement_df.prediction\n",
    "y_test = replacement_df.sentiment\n",
    "\n",
    "conf_matrix = pd.DataFrame(confusion_matrix(replacement_df.sentiment, replacement_df.prediction))\n",
    "print('Confusion Matrix')\n",
    "display(conf_matrix)\n",
    "\n",
    "test_scores = accuracy_score(y_test,predicted_classes), precision_score(y_test, predicted_classes), recall_score(y_test, predicted_classes), f1_score(y_test, predicted_classes)\n",
    "\n",
    "print('\\n \\n Scores')\n",
    "scores = pd.DataFrame(data=[test_scores])\n",
    "scores.columns = ['accuracy', 'precision', 'recall', 'f1']\n",
    "scores = scores.T\n",
    "scores.columns = ['scores']\n",
    "display(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
